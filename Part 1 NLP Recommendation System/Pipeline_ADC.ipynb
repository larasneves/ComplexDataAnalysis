{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\helen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\helen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\helen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ast\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split# as skl_train_test_split\n",
    "from datetime import datetime\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from surprise import accuracy\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\AppData\\Local\\Temp\\ipykernel_35232\\1838509011.py:7: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "\n",
    "df_business = pd.read_csv('yelp_academic_dataset_business.csv')\n",
    "df_checkin = pd.read_csv('yelp_academic_dataset_checkin.csv')\n",
    "df_review=pd.read_csv('yelp_academic_dataset_review.csv')\n",
    "df_tip=pd.read_csv('yelp_academic_dataset_tip.csv')\n",
    "df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n",
    "\n",
    "# print(df_business.columns)\n",
    "# print(df_checkin.columns)\n",
    "# print(df_review.columns)\n",
    "# print(df_tip.columns)\n",
    "# print(df_user.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset de dados\n",
    "\n",
    "df_business_filadelfia = df_business[(df_business['city'] == 'Philadelphia') & (df_business['categories'].str.contains('Restaurants', na=False)) & (df_business['is_open']==1)].reset_index(drop=True)\n",
    "df_business_filadelfia=df_business_filadelfia[['business_id', 'name', 'stars', 'review_count', 'attributes', 'categories', 'hours']].reset_index(drop=True)\n",
    "\n",
    "df_review_filadelfia = df_review[df_review['business_id'].isin(df_business_filadelfia['business_id'])]\n",
    "df_review_filadelfia=df_review_filadelfia[['review_id', 'user_id', 'business_id', 'stars', 'text', 'date']]\n",
    "df_review_filadelfia['liked'] = (df_review_filadelfia['stars'] > 3).astype(int)\n",
    "df_review_filadelfia_profiles = df_review_filadelfia[df_review_filadelfia['liked'] == 1].reset_index(drop=True)\n",
    "\n",
    "df_user_filadelfia = df_user[df_user['user_id'].isin(df_review_filadelfia['user_id'])]\n",
    "df_user_filadelfia=df_user_filadelfia[['user_id', 'name', 'review_count', 'yelping_since', 'elite', 'average_stars']].reset_index(drop=True)\n",
    "\n",
    "# Perfis LDA\n",
    "user_profile = pd.read_csv(\"user_profiles.csv\")\n",
    "user_profile = user_profile.drop(columns=['Unnamed: 0'])\n",
    "restaurant_profile = pd.read_csv(\"restaurant_profiles.csv\")\n",
    "restaurant_profile = restaurant_profile.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oyaMhzBSwfGgemSGuZCdwQ</td>\n",
       "      <td>Dd1jQj7S-BFGqRbApFzCFw</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tremendous service (Big shout out to Douglas) ...</td>\n",
       "      <td>2013-06-24 11:21:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Xs8Z8lmKkosqW5mw_sVAoA</td>\n",
       "      <td>IQsF3Rc6IgCzjVV9DE8KXg</td>\n",
       "      <td>eFvzHawVJofxSnD7TgbZtg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My absolute favorite cafe in the city. Their b...</td>\n",
       "      <td>2014-11-12 15:30:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>JBWZmBy69VMggxj3eYn17Q</td>\n",
       "      <td>aFa96pz67TwOFu4Weq5Agg</td>\n",
       "      <td>kq5Ghhh14r-eCxlVmlyd8w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My boyfriend and I tried this deli for the fir...</td>\n",
       "      <td>2018-08-23 21:39:38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>YcLXh-3UC9y6YFAI9xxzPQ</td>\n",
       "      <td>G0DHgkSsDozqUPWtlxVEMw</td>\n",
       "      <td>oBhJuukGRqPVvYBfTkhuZA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The only reason I didn't give this restaurant ...</td>\n",
       "      <td>2015-03-05 03:37:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990235</th>\n",
       "      <td>ZcEx4UEnTnR_TEPEqwkKjA</td>\n",
       "      <td>gkg9VqsxPCgpfYXO1dl8CA</td>\n",
       "      <td>Ea663rIHyKXz2VP2DPH7Cg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I decided to try this place out after Christma...</td>\n",
       "      <td>2020-01-13 04:21:38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990239</th>\n",
       "      <td>me7QTotYCOjWNVA8bzN1eg</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>wMQkdK2aNMvq2xoojC98Mw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>South Street Diner isn't the best of Philly Di...</td>\n",
       "      <td>2007-07-27 20:12:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990240</th>\n",
       "      <td>5n_oSwXspiiSsZgNwjp48g</td>\n",
       "      <td>bJ5FtCtZX3ZZacz2_2PJjA</td>\n",
       "      <td>SOsjW1JARmtHUFtpFlp8rw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>When I first heard that the Peace A Pizza (htt...</td>\n",
       "      <td>2017-02-23 19:11:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990255</th>\n",
       "      <td>MVg4YUQeEhCA7Z7RsBJSVg</td>\n",
       "      <td>7-7A0Avj47slLGV7yBFc8w</td>\n",
       "      <td>ytynqOUb3hjKeJfRj5Tshw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I was so excited about all the food I saw, but...</td>\n",
       "      <td>2013-07-25 21:00:15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990260</th>\n",
       "      <td>nLjbVsETpqO17RbFcqskkA</td>\n",
       "      <td>am7-gkH_PDz598oTdYSD6A</td>\n",
       "      <td>3gVSrS4kffGGZT8oXHsIcw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>*Later Yelp* I've only been here once, but I l...</td>\n",
       "      <td>2014-11-03 14:45:46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511138 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      review_id                 user_id  \\\n",
       "3        AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ   \n",
       "16       oyaMhzBSwfGgemSGuZCdwQ  Dd1jQj7S-BFGqRbApFzCFw   \n",
       "19       Xs8Z8lmKkosqW5mw_sVAoA  IQsF3Rc6IgCzjVV9DE8KXg   \n",
       "38       JBWZmBy69VMggxj3eYn17Q  aFa96pz67TwOFu4Weq5Agg   \n",
       "42       YcLXh-3UC9y6YFAI9xxzPQ  G0DHgkSsDozqUPWtlxVEMw   \n",
       "...                         ...                     ...   \n",
       "6990235  ZcEx4UEnTnR_TEPEqwkKjA  gkg9VqsxPCgpfYXO1dl8CA   \n",
       "6990239  me7QTotYCOjWNVA8bzN1eg  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990240  5n_oSwXspiiSsZgNwjp48g  bJ5FtCtZX3ZZacz2_2PJjA   \n",
       "6990255  MVg4YUQeEhCA7Z7RsBJSVg  7-7A0Avj47slLGV7yBFc8w   \n",
       "6990260  nLjbVsETpqO17RbFcqskkA  am7-gkH_PDz598oTdYSD6A   \n",
       "\n",
       "                    business_id  stars  \\\n",
       "3        kxX2SOes4o-D3ZQBkiMRfA    5.0   \n",
       "16       YtSqYv1Q_pOltsVPSx54SA    5.0   \n",
       "19       eFvzHawVJofxSnD7TgbZtg    5.0   \n",
       "38       kq5Ghhh14r-eCxlVmlyd8w    5.0   \n",
       "42       oBhJuukGRqPVvYBfTkhuZA    4.0   \n",
       "...                         ...    ...   \n",
       "6990235  Ea663rIHyKXz2VP2DPH7Cg    4.0   \n",
       "6990239  wMQkdK2aNMvq2xoojC98Mw    4.0   \n",
       "6990240  SOsjW1JARmtHUFtpFlp8rw    4.0   \n",
       "6990255  ytynqOUb3hjKeJfRj5Tshw    3.0   \n",
       "6990260  3gVSrS4kffGGZT8oXHsIcw    3.0   \n",
       "\n",
       "                                                      text  \\\n",
       "3        Wow!  Yummy, different,  delicious.   Our favo...   \n",
       "16       Tremendous service (Big shout out to Douglas) ...   \n",
       "19       My absolute favorite cafe in the city. Their b...   \n",
       "38       My boyfriend and I tried this deli for the fir...   \n",
       "42       The only reason I didn't give this restaurant ...   \n",
       "...                                                    ...   \n",
       "6990235  I decided to try this place out after Christma...   \n",
       "6990239  South Street Diner isn't the best of Philly Di...   \n",
       "6990240  When I first heard that the Peace A Pizza (htt...   \n",
       "6990255  I was so excited about all the food I saw, but...   \n",
       "6990260  *Later Yelp* I've only been here once, but I l...   \n",
       "\n",
       "                        date  liked  \n",
       "3        2015-01-04 00:01:03      1  \n",
       "16       2013-06-24 11:21:25      1  \n",
       "19       2014-11-12 15:30:27      1  \n",
       "38       2018-08-23 21:39:38      1  \n",
       "42       2015-03-05 03:37:54      1  \n",
       "...                      ...    ...  \n",
       "6990235  2020-01-13 04:21:38      1  \n",
       "6990239  2007-07-27 20:12:11      1  \n",
       "6990240  2017-02-23 19:11:04      1  \n",
       "6990255  2013-07-25 21:00:15      0  \n",
       "6990260  2014-11-03 14:45:46      0  \n",
       "\n",
       "[511138 rows x 7 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts\n",
    "user_counts = df_review_filadelfia['user_id'].value_counts()\n",
    "restaurant_counts = df_review_filadelfia['business_id'].value_counts()\n",
    "\n",
    "# creating filters for users and restaurants with 5+ reviews\n",
    "users_with_5_plus_reviews = user_counts[user_counts >= 5].index\n",
    "restaurants_with_5_plus_reviews = restaurant_counts[restaurant_counts >= 5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with 5+ reviews: 13948\n",
      "Number of restaurants reviewed 5+ times: 3040\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of users with 5+ reviews: {len(users_with_5_plus_reviews)}')\n",
    "print(f'Number of restaurants reviewed 5+ times: {len(restaurants_with_5_plus_reviews)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0464826958020617"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desired dataset shape\n",
    "#data = df_review_filadelfia_profiles[['user_id', 'business_id', 'text', 'stars']] # only positive reviews\n",
    "data = df_review_filadelfia[['user_id', 'business_id', 'text', 'stars']]\n",
    "\n",
    "data_sample = data.sample(100000, random_state=10).reset_index(drop=True)\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = skl_train_test_split(data_sample[['user_id', 'business_id', 'text']], data_sample['stars'], test_size=0.2, random_state=1)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# this outputs the topic matrix according to the method chosen (bag-of-word, lsa, lda and doc2vec) \n",
    "n_components = 8\n",
    "topic_matrix = feature_engineering(X_train, 'lda', n_components)\n",
    "\n",
    "# attach topic matrix to the dataset\n",
    "column_names = ['comp_{}'.format(i+1) for i in range(n_components)]\n",
    "topics = pd.DataFrame(topic_matrix, columns=column_names)\n",
    "\n",
    "# create profiles\n",
    "user_profile = pd.concat([X_train, topics], axis=1).drop(columns=['business_id', 'text']).groupby(\"user_id\", as_index=False)[column_names].mean()\n",
    "restaurant_profile = pd.concat([X_train, topics], axis=1).drop(columns=['user_id', 'text']).groupby(\"business_id\", as_index=False)[column_names].mean()\n",
    "\n",
    "# filtering for the ones with 5+ reviews (more representative)\n",
    "user_profile = user_profile[user_profile['user_id'].isin(users_with_5_plus_reviews)].reset_index(drop=True)\n",
    "restaurant_profile = restaurant_profile[restaurant_profile['business_id'].isin(restaurants_with_5_plus_reviews)].reset_index(drop=True)\n",
    "\n",
    "# predicting on the test set using the recommendations function\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='users'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# metrics\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.273092206852342"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# função para dar input de user e business e output de rating (recomendações)\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='items'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# avaliar no rating ground truth\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1661959908374837"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# função para dar input de user e business e output de rating (recomendações)\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='user_item'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# avaliar no rating ground truth\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0464826958020617"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# função para dar input de user e business e output de rating (recomendações)\n",
    "X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type='users'), axis=1)\n",
    "y = pd.concat([X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "# avaliar no rating ground truth\n",
    "np.sqrt(mean_squared_error(y['star_pred'], y['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rating(cosine_similarity):\n",
    "    '''\n",
    "    Maps a consine similarity score to a rating from 1 to 5\n",
    "    '''\n",
    "    return 1 + 4 * ((cosine_similarity + 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "def load_data():\n",
    "    # df_business = pd.read_csv('yelp_academic_dataset_business.csv')\n",
    "    # df_review=pd.read_csv('yelp_academic_dataset_review.csv')\n",
    "    # df_user=pd.read_csv('yelp_academic_dataset_user.csv')\n",
    "    \n",
    "    df_business_filadelfia = df_business[(df_business['city'] == 'Philadelphia') & (df_business['categories'].str.contains('Restaurants', na=False)) & (df_business['is_open']==1)].reset_index(drop=True)\n",
    "    df_business_filadelfia=df_business_filadelfia[['business_id', 'name', 'stars', 'review_count', 'attributes', 'categories', 'hours']].reset_index(drop=True)\n",
    "    df_business_filadelfia = df_business_filadelfia.dropna().reset_index(drop=True)\n",
    "\n",
    "    df_review_filadelfia = df_review[df_review['business_id'].isin(df_business_filadelfia['business_id'])]\n",
    "    df_review_filadelfia=df_review_filadelfia[['review_id', 'user_id', 'business_id', 'stars', 'text', 'date']]\n",
    "    df_review_filadelfia['liked'] = (df_review_filadelfia['stars'] > 3).astype(int)\n",
    "    df_review_filadelfia_profiles = df_review_filadelfia[df_review_filadelfia['liked'] == 1].reset_index(drop=True)\n",
    "    df_review_filadelfia = df_review_filadelfia.dropna().reset_index(drop=True)\n",
    "\n",
    "    df_user_filadelfia = df_user[df_user['user_id'].isin(df_review_filadelfia['user_id'])]\n",
    "    df_user_filadelfia=df_user_filadelfia[['user_id', 'name', 'review_count', 'yelping_since', 'elite', 'average_stars']].reset_index(drop=True)\n",
    "    df_user_filadelfia = df_user_filadelfia.dropna().reset_index(drop=True)\n",
    "\n",
    "    # counts\n",
    "    user_counts = df_review_filadelfia['user_id'].value_counts()\n",
    "    restaurant_counts = df_review_filadelfia['business_id'].value_counts()\n",
    "\n",
    "    # creating filters for users and restaurants with 5+ reviews\n",
    "    users_with_5_plus_reviews = user_counts[user_counts >= 5].index\n",
    "    restaurants_with_5_plus_reviews = restaurant_counts[restaurant_counts >= 5].index\n",
    "\n",
    "    return df_business_filadelfia,df_review_filadelfia,df_user_filadelfia, users_with_5_plus_reviews, restaurants_with_5_plus_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stem_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processamento\n",
    "def pre_processing(data_review,method):\n",
    "    if method == 'with lemma':\n",
    "\n",
    "        data_review['text'] = data_review['text'].apply(lemmatize_text)\n",
    "\n",
    "    \n",
    "    else: \n",
    "        data_review['text'] = data_review['text'].apply(stem_text)\n",
    "\n",
    "    return data_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>QS7CuOtFLuS3dnwKHRtSYQ</td>\n",
       "      <td>PBnEwGVCBL0N-bET6ZI6kQ</td>\n",
       "      <td>m5-FtgWRd4qA7j0vaOXiXQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Had to wait until my third trip to NOLA to act...</td>\n",
       "      <td>2016-11-10 20:56:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4PHFo_GRG4FEk1q4X7xQVQ</td>\n",
       "      <td>jbsCBG0A-3wVDjrKar-0Wg</td>\n",
       "      <td>X63jIMRHYBvKKQDuJTRiQQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A GREAT EXPERIENCE!!!!!!!!!  I was a completel...</td>\n",
       "      <td>2014-10-11 13:55:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1c6sgLe07HAhipebsQ1wgA</td>\n",
       "      <td>ZRXvbrutBBULaFS6T9NCwA</td>\n",
       "      <td>HnhxO2cpa15AHI1456Pl6Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Wow! I never thought my sons phone could be re...</td>\n",
       "      <td>2015-10-17 00:55:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PPgbLBvi34A6m7bKJfTwhw</td>\n",
       "      <td>3TL6HZ1JrKcNTvGDWKlrow</td>\n",
       "      <td>GyC36Pn0Q1-qHnqXys6yFg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Service and management terrible... After messi...</td>\n",
       "      <td>2013-12-07 13:17:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>gImS1dtA_TixEouDfp2o4g</td>\n",
       "      <td>xE7AXFF9wVaN6id6OCtH3Q</td>\n",
       "      <td>D5V0Fawd6ODVgqCY8xngsw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I have been to a number of dog friendly hotels...</td>\n",
       "      <td>2017-01-14 21:05:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 review_id                 user_id             business_id  \\\n",
       "0   KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1   BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2   saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3   AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4   Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "..                     ...                     ...                     ...   \n",
       "95  QS7CuOtFLuS3dnwKHRtSYQ  PBnEwGVCBL0N-bET6ZI6kQ  m5-FtgWRd4qA7j0vaOXiXQ   \n",
       "96  4PHFo_GRG4FEk1q4X7xQVQ  jbsCBG0A-3wVDjrKar-0Wg  X63jIMRHYBvKKQDuJTRiQQ   \n",
       "97  1c6sgLe07HAhipebsQ1wgA  ZRXvbrutBBULaFS6T9NCwA  HnhxO2cpa15AHI1456Pl6Q   \n",
       "98  PPgbLBvi34A6m7bKJfTwhw  3TL6HZ1JrKcNTvGDWKlrow  GyC36Pn0Q1-qHnqXys6yFg   \n",
       "99  gImS1dtA_TixEouDfp2o4g  xE7AXFF9wVaN6id6OCtH3Q  D5V0Fawd6ODVgqCY8xngsw   \n",
       "\n",
       "    stars  useful  funny  cool  \\\n",
       "0     3.0       0      0     0   \n",
       "1     5.0       1      0     1   \n",
       "2     3.0       0      0     0   \n",
       "3     5.0       1      0     1   \n",
       "4     4.0       1      0     1   \n",
       "..    ...     ...    ...   ...   \n",
       "95    5.0       0      0     0   \n",
       "96    5.0       2      0     1   \n",
       "97    5.0       0      1     0   \n",
       "98    1.0       0      0     0   \n",
       "99    4.0       1      0     2   \n",
       "\n",
       "                                                 text                 date  \n",
       "0   If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n",
       "1   I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n",
       "2   Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n",
       "3   Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n",
       "4   Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  \n",
       "..                                                ...                  ...  \n",
       "95  Had to wait until my third trip to NOLA to act...  2016-11-10 20:56:13  \n",
       "96  A GREAT EXPERIENCE!!!!!!!!!  I was a completel...  2014-10-11 13:55:05  \n",
       "97  Wow! I never thought my sons phone could be re...  2015-10-17 00:55:35  \n",
       "98  Service and management terrible... After messi...  2013-12-07 13:17:13  \n",
       "99  I have been to a number of dog friendly hotels...  2017-01-14 21:05:04  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = df_review[:100]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "def feature_engineering(data_reviews, method, components=8):\n",
    "    if method == 'bag of words':\n",
    "        vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "        matrix = vectorizer.fit_transform(data_reviews['text'])\n",
    "        matrix = matrix.toarray()\n",
    "        components = matrix.shape[1]\n",
    "        # feature_names = vectorizer.get_feature_names_out()\n",
    "        # df = pd.DataFrame(matrix, columns=feature_names)\n",
    "   \n",
    "    elif method =='lda':\n",
    "        count_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "        count_matrix = count_vectorizer.fit_transform(data_reviews['text'])\n",
    "        lda_model = LatentDirichletAllocation(n_components=components, random_state=42)\n",
    "        matrix = lda_model.fit_transform(count_matrix)\n",
    "        # df = pd.DataFrame(matrix, columns=[f'Topic_{i}' for i in range(lda_model.n_components)])\n",
    "    \n",
    "    elif method =='lsa':\n",
    "        vectorizer = CountVectorizer()\n",
    "        count_matrix = vectorizer.fit_transform(data_reviews['text'])\n",
    "        lsa_model = TruncatedSVD(n_components=components)\n",
    "        matrix = lsa_model.fit_transform(count_matrix)\n",
    "\n",
    "    elif method == 'doc2vec':\n",
    "        # preproces the documents, and create TaggedDocuments\n",
    "        tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()),\n",
    "                                    tags=[str(i)]) for i,\n",
    "                    doc in enumerate(data_reviews['text'])]\n",
    "\n",
    "        # Doc2vec model\n",
    "        model = Doc2Vec(vector_size=components,\n",
    "                        min_count=2, epochs=50)\n",
    "        model.build_vocab(tagged_data)\n",
    "        model.train(tagged_data,\n",
    "                    total_examples=model.corpus_count,\n",
    "                    epochs=model.epochs)\n",
    "\n",
    "        # document vectors\n",
    "        matrix = [model.infer_vector(\n",
    "            word_tokenize(doc.lower())) for doc in data_reviews['text']]\n",
    "\n",
    "    return matrix, components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_business(df_business_filadelfia):\n",
    "    df_business_filadelfia = df_business_filadelfia[['business_id', 'name', 'stars', 'review_count','attributes', 'categories', 'hours']]\n",
    "\n",
    "\n",
    "    #variavel horario\n",
    "    df_business_filadelfia['hours'] = df_business_filadelfia['hours'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else {})\n",
    "\n",
    "    # Crie colunas separadas para cada dia da semana\n",
    "    dias_da_semana = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    for dia in dias_da_semana:\n",
    "        df_business_filadelfia[dia] = df_business_filadelfia['hours'].apply(lambda x: x.get(dia, None))\n",
    "\n",
    "    # Remova a coluna original 'hours' se não for mais necessária\n",
    "    df_business_filadelfia.drop(columns=['hours'], inplace=True)\n",
    "\n",
    "\n",
    "    def categorize_hours(hours):\n",
    "\n",
    "        if hours == None:\n",
    "            return 0 #'Fechado'\n",
    "        \n",
    "        else:\n",
    "            start_time, end_time = hours.split('-')\n",
    "            start_hour = int(start_time.split(':')[0])\n",
    "            end_hour = int(end_time.split(':')[0])\n",
    "            \n",
    "            if end_hour <= 12:\n",
    "                return 1 #'Manhã'\n",
    "            elif 12 < start_hour and end_hour<=15:\n",
    "                return 2 #'Almoço'\n",
    "            elif start_hour > 15 and end_hour < 19:\n",
    "                return 3 #'Tarde'\n",
    "            elif start_hour>=19:\n",
    "                return 4 #'Noite'\n",
    "            else:\n",
    "                return 5 #'Dia todo'\n",
    "\n",
    "    # Aplicar a função de categorização a cada coluna de dia da semana\n",
    "    for day in ['Monday', 'Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "        df_business_filadelfia[day] = df_business_filadelfia[day].apply(categorize_hours)\n",
    "\n",
    "\n",
    "    #variavel categoria\n",
    "\n",
    "    df_business_filadelfia['Restaurants'] = 0\n",
    "    df_business_filadelfia['Food'] = 0\n",
    "    df_business_filadelfia['Nightlife'] = 0\n",
    "    df_business_filadelfia['Bars'] = 0\n",
    "    df_business_filadelfia['Sandwiches'] = 0\n",
    "    df_business_filadelfia['American (New)'] = 0\n",
    "    df_business_filadelfia['Pizza'] = 0\n",
    "    df_business_filadelfia['Breakfast & Brunch'] = 0\n",
    "    df_business_filadelfia['American (Traditional)'] = 0\n",
    "    df_business_filadelfia['Coffee & Tea'] = 0\n",
    "\n",
    "    for index, row in df_business_filadelfia.iterrows():\n",
    "        categories = row['categories']\n",
    "        if 'Restaurants' in categories:\n",
    "            df_business_filadelfia.at[index, 'Restaurantes'] = 1\n",
    "\n",
    "        if 'Food' in categories:\n",
    "            df_business_filadelfia.at[index, 'Food'] = 1\n",
    "\n",
    "        if 'Nightlife' in categories:\n",
    "            df_business_filadelfia.at[index, 'Nightlife'] = 1\n",
    "\n",
    "        if 'Bars' in categories:\n",
    "            df_business_filadelfia.at[index, 'Bars'] = 1\n",
    "\n",
    "        if 'Sandwiches' in categories:\n",
    "            df_business_filadelfia.at[index, 'Sandwiches'] = 1\n",
    "\n",
    "        if 'American (New)' in categories:\n",
    "            df_business_filadelfia.at[index, 'American (New)'] = 1\n",
    "        \n",
    "        if 'Pizza' in categories:\n",
    "            df_business_filadelfia.at[index, 'Pizza'] = 1\n",
    "\n",
    "        if 'Breakfast & Brunch' in categories:\n",
    "            df_business_filadelfia.at[index, 'Breakfast & Brunch'] = 1\n",
    "\n",
    "        if 'American (Traditional)' in categories:\n",
    "            df_business_filadelfia.at[index, 'American (Traditional)'] = 1\n",
    "\n",
    "        if 'Coffee & Tea' in categories:\n",
    "            df_business_filadelfia.at[index, 'Coffee & Tea'] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #variavel atributos\n",
    "\n",
    "        df_business_filadelfia['RestaurantsDelivery'] = 0\n",
    "        df_business_filadelfia['OutdoorSeating'] = 0\n",
    "        df_business_filadelfia['BusinessAcceptsCreditCards'] = 0\n",
    "        df_business_filadelfia['BikeParking'] = 0\n",
    "        df_business_filadelfia['RestaurantsTakeOut'] = 0\n",
    "        df_business_filadelfia['ByAppointmentOnly'] = 0\n",
    "        df_business_filadelfia['Caters'] = 0\n",
    "        df_business_filadelfia['RestaurantsReservations'] = 0\n",
    "        df_business_filadelfia['RestaurantsGoodForGroups'] = 0\n",
    "        df_business_filadelfia['HasTV'] = 0\n",
    "        df_business_filadelfia['GoodForKids'] = 0\n",
    "        df_business_filadelfia['DogsAllowed'] = 0\n",
    "        df_business_filadelfia['HappyHour'] = 0\n",
    "        df_business_filadelfia['WheelchairAccessible'] = 0\n",
    "        df_business_filadelfia['RestaurantsTableService'] = 0\n",
    "        df_business_filadelfia['BusinessAcceptsBitcoin'] = 0\n",
    "        df_business_filadelfia['Corkage'] = 0\n",
    "        df_business_filadelfia['CoatCheck'] = 0\n",
    "        df_business_filadelfia['BYOB'] = 0\n",
    "        df_business_filadelfia['DriveThru'] = 0\n",
    "\n",
    "\n",
    "        for index, row in df_business_filadelfia.iterrows():\n",
    "            categories = row['categories']\n",
    "            if 'RestaurantsDelivery' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsDelivery'] = 1\n",
    "\n",
    "            if 'OutdoorSeating' in categories:\n",
    "                df_business_filadelfia.at[index, 'OutdoorSeating'] = 1\n",
    "\n",
    "            if 'BusinessAcceptsCreditCards' in categories:\n",
    "                df_business_filadelfia.at[index, 'BusinessAcceptsCreditCards'] = 1\n",
    "\n",
    "            if 'BikeParking' in categories:\n",
    "                df_business_filadelfia.at[index, 'BikeParking'] = 1\n",
    "\n",
    "            if 'RestaurantsTakeOut' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsTakeOut'] = 1\n",
    "\n",
    "            if 'ByAppointmentOnly' in categories:\n",
    "                df_business_filadelfia.at[index, 'ByAppointmentOnly'] = 1\n",
    "            \n",
    "            if 'Caters' in categories:\n",
    "                df_business_filadelfia.at[index, 'Caters'] = 1\n",
    "\n",
    "            if 'RestaurantsReservations' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsReservations'] = 1\n",
    "\n",
    "            if 'RestaurantsGoodForGroups' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsGoodForGroups'] = 1\n",
    "\n",
    "            if 'HasTV' in categories:\n",
    "                df_business_filadelfia.at[index, 'HasTV'] = 1\n",
    "\n",
    "            if 'GoodForKids' in categories:\n",
    "                df_business_filadelfia.at[index, 'GoodForKids'] = 1\n",
    "\n",
    "            if 'DogsAllowed' in categories:\n",
    "                df_business_filadelfia.at[index, 'DogsAllowed'] = 1\n",
    "\n",
    "            if 'HappyHour' in categories:\n",
    "                df_business_filadelfia.at[index, 'HappyHour'] = 1\n",
    "\n",
    "            if 'WheelchairAccessible' in categories:\n",
    "                df_business_filadelfia.at[index, 'WheelchairAccessible'] = 1\n",
    "\n",
    "            if 'RestaurantsTableService' in categories:\n",
    "                df_business_filadelfia.at[index, 'RestaurantsTableService'] = 1\n",
    "\n",
    "            if 'BusinessAcceptsBitcoin' in categories:\n",
    "                df_business_filadelfia.at[index, 'BusinessAcceptsBitcoin'] = 1\n",
    "\n",
    "            if 'Corkage' in categories:\n",
    "                df_business_filadelfia.at[index, 'Corkage'] = 1\n",
    "            \n",
    "            if 'CoatCheck' in categories:\n",
    "                df_business_filadelfia.at[index, 'CoatCheck'] = 1\n",
    "\n",
    "            if 'BYOB' in categories:\n",
    "                df_business_filadelfia.at[index, 'BYOB'] = 1\n",
    "\n",
    "            if 'DriveThru' in categories:\n",
    "                df_business_filadelfia.at[index, 'DriveThru'] = 1\n",
    "\n",
    "        df_business_filadelfia.columns = ['business_id', 'name', 'stars', 'review_count_business', 'attributes', 'categories', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',\n",
    "       'Saturday', 'Sunday', 'Restaurants', 'Food', 'Nightlife', 'Bars', 'Sandwiches', 'American (New)', 'Pizza', 'Breakfast & Brunch', 'American (Traditional)', 'Coffee & Tea', 'Restaurantes',\n",
    "       'RestaurantsDelivery', 'OutdoorSeating', 'BusinessAcceptsCreditCards', 'BikeParking', 'RestaurantsTakeOut', 'ByAppointmentOnly', 'Caters','RestaurantsReservations', 'RestaurantsGoodForGroups', 'HasTV',\n",
    "       'GoodForKids', 'DogsAllowed', 'HappyHour', 'WheelchairAccessible','RestaurantsTableService', 'BusinessAcceptsBitcoin', 'Corkage','CoatCheck', 'BYOB', 'DriveThru']\n",
    "        \n",
    "        df_business_filadelfia=df_business_filadelfia.drop(['attributes', 'categories','name'],axis=1)\n",
    "\n",
    "        return df_business_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_user(df_user_filadelfia):\n",
    "\n",
    "\n",
    "    yelping_since = pd.to_datetime(df_user_filadelfia['yelping_since'])\n",
    "\n",
    "    # Calcule o número de anos no Yelp\n",
    "    current_year = datetime.now().year\n",
    "    df_user_filadelfia['yelping_since'] = current_year - yelping_since.dt.year\n",
    "\n",
    "\n",
    "    df_user_filadelfia.columns = ['user_id', 'name', 'review_count_user', 'yelping_years', 'elite', 'average_stars']\n",
    "    df_user_filadelfia=df_user_filadelfia.drop(['elite','name'],axis=1)\n",
    "    # df_user_filadelfia=df_user_filadelfia.drop('yelping_since',axis=1)\n",
    "\n",
    "        \n",
    "\n",
    "    return df_user_filadelfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profiling(X_train, method, n_components, users_with_5_plus_reviews, restaurants_with_5_plus_reviews):\n",
    "    \n",
    "    # this outputs the topic matrix according to the method chosen (bag-of-word, lsa, lda and doc2vec) \n",
    "    topic_matrix, n_components = feature_engineering(X_train, method, n_components)\n",
    "\n",
    "    # attach topic matrix to the dataset\n",
    "    column_names = ['comp_{}'.format(i+1) for i in range(n_components)]\n",
    "    topics = pd.DataFrame(topic_matrix, columns=column_names)\n",
    "\n",
    "    # create profiles\n",
    "    user_profile = pd.concat([X_train, topics], axis=1).drop(columns=['business_id', 'text']).groupby(\"user_id\", as_index=False)[column_names].mean()\n",
    "    restaurant_profile = pd.concat([X_train, topics], axis=1).drop(columns=['user_id', 'text']).groupby(\"business_id\", as_index=False)[column_names].mean()\n",
    "\n",
    "    # filtering for the ones with 5+ reviews (more representative)\n",
    "    user_profile = user_profile[user_profile['user_id'].isin(users_with_5_plus_reviews)].reset_index(drop=True)\n",
    "    restaurant_profile = restaurant_profile[restaurant_profile['business_id'].isin(restaurants_with_5_plus_reviews)].reset_index(drop=True)\n",
    "\n",
    "    return user_profile, restaurant_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df_review_filadelfia):\n",
    "    # Desired dataset shape\n",
    "    #data = df_review_filadelfia_profiles[['user_id', 'business_id', 'text', 'stars']] # only positive reviews\n",
    "    data = df_review_filadelfia[['user_id', 'business_id', 'text', 'stars']]\n",
    "\n",
    "    #data_sample = data.sample(100000, random_state=10).reset_index(drop=True)\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[['user_id', 'business_id', 'text']], data['stars'], test_size=0.2, random_state=1)\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation system\n",
    "\n",
    "def recommend(user_id, restaurant_id, df_review_filadelfia, user_profile, restaurant_profile, type):\n",
    "    \n",
    "    '''\n",
    "    Estimates rating a user gives to a restaurant\n",
    "\n",
    "    Inputs:\n",
    "    user_id - the user\n",
    "    restaurant_id - the restaurant to be rated\n",
    "    df_review_filadelfia - original df with no filtering regarding the review being positive or not\n",
    "    user_profile - df with the profiles of the users (vectors from LSA/LDA/doc2vec)\n",
    "    restaurant_profile - df with the profiles of the restaurants (vectors from LSA/LDA/doc2vec)\n",
    "    type - type of recommendations (user_item, users or items) (default = \"user_item\")\n",
    "\n",
    "    Outputs:\n",
    "    Rating\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Extracting the vector relative to the user and removing the user from the profiles\n",
    "        usr_lst = user_profile[user_profile['user_id'] == user_id].drop(columns=['user_id']).fillna(0).values\n",
    "        user_profile_function = user_profile[user_profile['user_id'] != user_id].reset_index(drop=True).fillna(0)\n",
    "        \n",
    "        # Extracting the vector relative to the restaurant and removing the restaurant from the profiles\n",
    "        bus_lst = restaurant_profile[restaurant_profile['business_id'] == restaurant_id].drop(columns=['business_id']).fillna(0).values\n",
    "        restaurant_profile_function = restaurant_profile[restaurant_profile['business_id'] != restaurant_id].reset_index(drop=True).fillna(0)\n",
    "\n",
    "\n",
    "        if type == 'UIBH':\n",
    "            # Measures the similarity between user and restaurant\n",
    "            # Rating is a linear function of the similarity\n",
    "\n",
    "            # Removing the added feature so that the vectors have the same dimensions\n",
    "            usr_lst = usr_lst[:,:-3]\n",
    "            bus_lst = bus_lst[:,:-40]\n",
    "\n",
    "            similarity_score = cosine_similarity(usr_lst, bus_lst)\n",
    "            rating = map_rating(similarity_score[0][0])\n",
    "            \n",
    "        elif type == 'UBH':\n",
    "            # Measures the similarity between the user and the other users that rated the restaurant\n",
    "            # Rating is a weighted average of the ratings given by the users (weighted by the similarity)\n",
    "\n",
    "            # Getting the other users that rated the restaurant and removing user\n",
    "            users = df_review_filadelfia[df_review_filadelfia['business_id'] == restaurant_id]['user_id']\n",
    "            users = users[users != user_id]\n",
    "\n",
    "            # Due to considering only the positive reviews for the profiles, some users don't have profile\n",
    "            # This is to remove them from the users list\n",
    "            users = users[users.isin(user_profile_function['user_id'])].unique() # and remove duplicates\n",
    "\n",
    "            # Getting the ratings given by the users and averaging if there are more than one\n",
    "            users_ratings = df_review_filadelfia[df_review_filadelfia['user_id'].isin(users)][['user_id', 'stars']]\n",
    "            users_ratings = users_ratings.groupby('user_id').mean().reset_index()\n",
    "\n",
    "            # Creating a matrix for the similar users\n",
    "            user_matrix = user_profile_function[user_profile_function['user_id'].isin(users)].drop(columns=['user_id']).values\n",
    "\n",
    "            # Similarities between user and users\n",
    "            similarity_scores = cosine_similarity(usr_lst, user_matrix)\n",
    "\n",
    "            # Transform similarities into weights\n",
    "            # This assumes that there will be other similar users.\n",
    "            # If all the other users are not similar we are giving high weights to \"not similar\" users due to this rescaling\n",
    "            similarity_scores = (similarity_scores+1)/2\n",
    "            weights = similarity_scores / np.sum(similarity_scores, axis=1)\n",
    "\n",
    "            # Computing weight-averaged rating\n",
    "            rating = np.dot(weights[0], users_ratings['stars'])\n",
    "\n",
    "        elif type == 'IBH':\n",
    "            # Measures the similarity between the restaurant and other \n",
    "            # Recommends the restaurants that are most similar to the ones the user liked before\n",
    "\n",
    "            # Getting the other restaurants the user rated and removing the restaurant\n",
    "            restaurants = df_review_filadelfia[df_review_filadelfia['user_id'] == user_id]['business_id']\n",
    "            restaurants = restaurants[restaurants != restaurant_id]\n",
    "\n",
    "            # Due to considering only the positive reviews for the profiles, some restaurants don't have profile\n",
    "            # This is to remove them from the restaurants list\n",
    "            restaurants = restaurants[restaurants.isin(restaurant_profile_function['business_id'])].unique() # and remove duplicates\n",
    "\n",
    "            # Getting the ratings given by the user and averaging if there are more than one\n",
    "            user_ratings = df_review_filadelfia[df_review_filadelfia['user_id'] == user_id][['business_id', 'stars']]\n",
    "            user_ratings = user_ratings[user_ratings['business_id'].isin(restaurants)].reset_index(drop=True)\n",
    "            user_ratings = user_ratings.groupby('business_id').mean().reset_index()\n",
    "\n",
    "            # Creating a matrix for the similar restaurants\n",
    "            restaurant_matrix = restaurant_profile_function[restaurant_profile_function['business_id'].isin(restaurants)].drop(columns=['business_id']).fillna(0).values\n",
    "\n",
    "            # Similarities between the restaurant and the other restaurants\n",
    "            similarity_scores = cosine_similarity(bus_lst, restaurant_matrix)\n",
    "\n",
    "            # Transform similarities into weights\n",
    "            # This assumes that there will be other similar restaurants.\n",
    "            # If all the other restaurants are not similar we are giving high weights to \"not similar\" restaurants due to this rescaling\n",
    "            similarity_scores = (similarity_scores+1)/2\n",
    "            weights = similarity_scores / np.sum(similarity_scores, axis=1)\n",
    "\n",
    "            # Computing weight-averaged rating\n",
    "            rating = np.dot(weights[0], user_ratings['stars'])\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Invalid type. Please choose 'UIBH', 'UBH', or 'IBH'.\")\n",
    "        \n",
    "        return rating\n",
    "    \n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ground_truth, recommendations, k):\n",
    "\n",
    "    #top k predicted restaurants\n",
    "    top_k_pred = recommendations[:k]\n",
    "    \n",
    "    #top k user preferred restaurants\n",
    "    top_k_true = ground_truth[:k]\n",
    "    \n",
    "    # number of relevant items in the top k predictions\n",
    "    relevant = len(set(top_k_pred) & set(top_k_true))\n",
    "    \n",
    "    return relevant / k\n",
    "\n",
    "\n",
    "def recall_at_k(ground_truth, recommendations, k):\n",
    "\n",
    "    # top k predicted restaurants\n",
    "    top_k_pred = recommendations[:k]\n",
    "    \n",
    "    # total number of preferred restaurants\n",
    "    total_relevant = len(ground_truth)\n",
    "    \n",
    "    #number of relevant items in the top k predictions\n",
    "    relevant = len(set(top_k_pred) & set(ground_truth))\n",
    "    \n",
    "    return relevant / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "# TEMOS QUE APLICAR ISTO A CADA USER. TEMOS QUE TER UMA FUNÇÃO QUE PARA O USER DÁ TAMBÉM UM RANKING DE RESTAURANTES\n",
    "# COM ESSE RANKING CALCULAR PRECISION E RECALL @ K\n",
    "# E DEPOIS CALCULAR A MÉDIA DE TODOS OS USERS PARA ESSE MÉTODO\n",
    "\n",
    "# OU ENTÃO AGRUPAR AS PEDICTIONS POR USER E ASSUMIR ESSE RANKING\n",
    "# MARTELAR PARA SEREM SÓ USERS COM MAIS DE K REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate(X_test, y_test, df_review_filadelfia, user_profile, restaurant_profile, method):\n",
    "    # predicting on the test set using the recommendations function\n",
    "    X_test['star_pred'] = X_test.apply(lambda row: recommend(row['user_id'], row['business_id'], df_review_filadelfia, user_profile, restaurant_profile, type=method), axis=1)\n",
    "    y = pd.concat([X_test['business_id'], X_test['star_pred'], y_test], axis=1).dropna()\n",
    "\n",
    "    # metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y['star_pred'], y['stars']))\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods_pre_processing = ['with lemma','with stemma']\n",
    "methods_pre_processing = ['with lemma']\n",
    "# methods_feature_engineering = ['bag of words', 'word embeddings', 'lda']\n",
    "# methods_feature_engineering = ['bag of words','lda', 'lsa', 'doc2vec']\n",
    "methods_feature_engineering = ['lda', 'lsa', 'doc2vec']\n",
    "add_features_decision = ['yes','no']\n",
    "algorithms_cf = ['CF-UB','CF-IB'] #CF-IB(Colaborative Filtering Item Based),CF-UB(Colaborative Filtering User Based)\n",
    "algorithms_content = ['UBH','IBH','UIBH'] #UBH(User Based Hybrid), IBH(Item Based Hybrid), UIBH(User Item Based Hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main J\n",
    "\n",
    "def main():\n",
    "\n",
    "    rmse_df = pd.DataFrame(columns=['Pre-processing', 'Feature Engineering', 'Algorithm', 'RMSE'])\n",
    "\n",
    "    # Load the dataset\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia, users_with_5_plus_reviews, restaurants_with_5_plus_reviews = load_data()\n",
    "\n",
    "    df_review_filadelfia = df_review_filadelfia.sample(1000, random_state=10).reset_index(drop=True) # TO TEST AND DELETE AFTER\n",
    "\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = split(df_review_filadelfia)\n",
    "\n",
    "    users_train = X_train['user_id']\n",
    "\n",
    "    businesses_train = X_train['business_id']\n",
    "\n",
    "    df_user_filadelfia_treino = df_user_filadelfia[df_user_filadelfia['user_id'].isin(users_train)]\n",
    "\n",
    "    df_business_filadelfia_treino = df_business_filadelfia[df_business_filadelfia['business_id'].isin(businesses_train)]\n",
    "\n",
    "    df_features_user = features_user(df_user_filadelfia_treino)\n",
    "    df_features_business = features_business(df_business_filadelfia_treino)\n",
    "\n",
    "    # Collaborative Filtering\n",
    "    for a in algorithms_cf:\n",
    "        train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "        # Combinar X_test e y_test para formar o DataFrame de teste\n",
    "        test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "        # Definir o Reader com a escala de classificação\n",
    "        reader = Reader(rating_scale=(df_review_filadelfia.stars.min(), df_review_filadelfia.stars.max()))\n",
    "\n",
    "        train_dataset = Dataset.load_from_df(train_data[['user_id', 'business_id', 'stars']], reader)\n",
    "        trainset = train_dataset.build_full_trainset()\n",
    "\n",
    "        # Carregar os dados de teste no formato Surprise\n",
    "        test_dataset = Dataset.load_from_df(test_data[['user_id', 'business_id', 'stars']], reader)\n",
    "        testset = [(uid, iid, true_r) for (uid, iid, true_r) in test_data[['user_id', 'business_id', 'stars']].values]\n",
    "\n",
    "        if a == 'CF-UB':\n",
    "            algo = KNNBasic(sim_options={'user_based': True})\n",
    "        else:\n",
    "            algo = KNNBasic(sim_options={'user_based': False})\n",
    "\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "\n",
    "        rmse_df = rmse_df.append({'Pre-processing': None, 'Feature Engineering': None, 'Algorithm': a, 'RMSE': rmse}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Content-based / Hybrid\n",
    "    for a in methods_pre_processing:\n",
    "        X_train_pre_processed = pre_processing(X_train, a)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "\n",
    "            if b == 'doc2vec':\n",
    "                n_components = 100\n",
    "            else:\n",
    "                n_components = 8\n",
    "\n",
    "            user_profile, restaurant_profile = profiling(X_train_pre_processed, b, n_components, users_with_5_plus_reviews, restaurants_with_5_plus_reviews)\n",
    "\n",
    "            user_profile=user_profile.merge(df_features_user,on='user_id')\n",
    "            restaurant_profile=restaurant_profile.merge(df_features_business,on='business_id')\n",
    "\n",
    "            for c in algorithms_content:\n",
    "                # return(X_test, y_test, user_profile, restaurant_profile, df_review_filadelfia)\n",
    "                rmse = test_evaluate(X_test, y_test, df_review_filadelfia, user_profile, restaurant_profile, c)\n",
    "                # return rmse\n",
    "                print(f'{a} - {b} - {c} - {rmse}')\n",
    "                rmse_df = rmse_df.append({'Pre-processing': a, 'Feature Engineering': b, 'Algorithm': c, 'RMSE': rmse}, ignore_index=True)\n",
    "\n",
    "    return rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\AppData\\Local\\Temp\\ipykernel_35232\\3323469296.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_user_filadelfia['yelping_since'] = current_year - yelping_since.dt.year\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3390388343883086"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "feature_engineering_method = []\n",
    "algoritmo=[]\n",
    "accuracy = []\n",
    "precision = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "\n",
    "def main():\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia = load_data()\n",
    "\n",
    "    df_business_filadelfia=df_business_filadelfia.sample(1000)\n",
    "    df_review_filadelfia=df_review_filadelfia.sample(1000)\n",
    "    df_user_filadelfia=df_user_filadelfia.sample(1000)\n",
    "\n",
    "    for a in algorithms_cf:\n",
    "        if a == 'CF-UB':\n",
    "            algo = KNNBasic(sim_options={'user_based': True})\n",
    "            algo.fit(user_trainset)\n",
    "            predictions = algo.test(user_testset)\n",
    "\n",
    "        else:\n",
    "\n",
    "            algo = KNNBasic(sim_options={'user_based': False})\n",
    "            algo.fit(business_trainset)\n",
    "            predictions = algo.test(business_testset)  \n",
    "\n",
    "\n",
    "    for a in methods_pre_processing:\n",
    "        df_review_filadelfia_pre_processado = pre_processing(df_review_filadelfia,a)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "            matrix = feature_engineering(df_review_filadelfia_pre_processado,b)\n",
    "\n",
    "            for c in algorithms_content:\n",
    "                df_review_filadelfia = df_review_filadelfia.reset_index(drop=True)\n",
    "\n",
    "                if c == 'UBH':\n",
    "                    matrix_per_user = df_review_filadelfia.groupby('user_id').apply(lambda x: np.mean(matrix[x.index], axis=0))\n",
    "                    features = features_user(df_user_filadelfia)\n",
    "\n",
    "                    matrix_df = pd.DataFrame(matrix_per_user.tolist(), index=matrix_per_user.index)\n",
    "\n",
    "                    # Adiciona a coluna 'user_id' ao DataFrame\n",
    "                    matrix_df.reset_index(inplace=True)\n",
    "\n",
    "                    # Junta as features à matriz\n",
    "                    result_df = matrix_df.merge(features, on='user_id')\n",
    "\n",
    "                    result_matrix = result_df.set_index('user_id').to_numpy()\n",
    "\n",
    "                    similarity_matrix = cosine_similarity(result_matrix)\n",
    "\n",
    "                if c == 'IBH':\n",
    "                    matrix_per_business = df_review_filadelfia.groupby('business_id').apply(lambda x: np.mean(matrix[x.index], axis=0))\n",
    "                    features = features_business(df_business_filadelfia)\n",
    "\n",
    "                    matrix_df = pd.DataFrame(matrix_per_business.tolist(), index=matrix_per_business.index)\n",
    "\n",
    "                    # Adiciona a coluna 'business_id' ao DataFrame\n",
    "                    matrix_df.reset_index(inplace=True)\n",
    "\n",
    "                    # Junta as features à matriz\n",
    "                    result_df = matrix_df.merge(features, on='business_id')\n",
    "\n",
    "                    result_matrix = result_df.set_index('business_id').to_numpy()\n",
    "\n",
    "                    #há restaurantes na matriz que não têm info nas features, mas agora já não consigo pensar\n",
    "\n",
    "                    similarity_matrix = cosine_similarity(result_matrix)\n",
    "\n",
    "\n",
    "                return similarity_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99544841, 0.9956561 , 0.99550571, 0.99320691,\n",
       "        0.99512158, 0.97249916, 0.99370598, 0.99560994, 0.99512402,\n",
       "        0.99566465, 0.99468465, 0.99510445, 0.99554181, 0.96953973,\n",
       "        0.99503323, 0.9954954 ],\n",
       "       [0.99544841, 1.        , 0.99861204, 0.99838974, 0.99591978,\n",
       "        0.99783472, 0.97700643, 0.99572167, 0.99871058, 0.99854622,\n",
       "        0.99869774, 0.99812797, 0.99797965, 0.99823546, 0.97154531,\n",
       "        0.99753358, 0.99831295],\n",
       "       [0.9956561 , 0.99861204, 1.        , 0.99958286, 0.99581111,\n",
       "        0.99938824, 0.97197443, 0.99640836, 0.9996102 , 0.99791619,\n",
       "        0.99928982, 0.99789648, 0.9978941 , 0.99941018, 0.96858762,\n",
       "        0.99865675, 0.99908913],\n",
       "       [0.99550571, 0.99838974, 0.99958286, 1.        , 0.99542662,\n",
       "        0.99978773, 0.96997742, 0.99636747, 0.99980537, 0.99736553,\n",
       "        0.99929694, 0.99763979, 0.99757971, 0.99964525, 0.96656999,\n",
       "        0.99882205, 0.99913428],\n",
       "       [0.99320691, 0.99591978, 0.99581111, 0.99542662, 1.        ,\n",
       "        0.99487779, 0.97450271, 0.9933151 , 0.9958191 , 0.99562086,\n",
       "        0.99595091, 0.99541835, 0.99558296, 0.99546823, 0.97000559,\n",
       "        0.99466321, 0.99557276],\n",
       "       [0.99512158, 0.99783472, 0.99938824, 0.99978773, 0.99487779,\n",
       "        1.        , 0.96757255, 0.99618468, 0.99963128, 0.99657858,\n",
       "        0.99894003, 0.99684643, 0.99690875, 0.99955955, 0.96492698,\n",
       "        0.99881262, 0.99891396],\n",
       "       [0.97249916, 0.97700643, 0.97197443, 0.96997742, 0.97450271,\n",
       "        0.96757255, 1.        , 0.97048659, 0.97125869, 0.9801121 ,\n",
       "        0.97352418, 0.97782985, 0.97697623, 0.97078765, 0.96870977,\n",
       "        0.96917797, 0.97255484],\n",
       "       [0.99370598, 0.99572167, 0.99640836, 0.99636747, 0.9933151 ,\n",
       "        0.99618468, 0.97048659, 1.        , 0.99651403, 0.99497372,\n",
       "        0.99651817, 0.99579263, 0.99490862, 0.99630712, 0.97043658,\n",
       "        0.99605613, 0.99604521],\n",
       "       [0.99560994, 0.99871058, 0.9996102 , 0.99980537, 0.9958191 ,\n",
       "        0.99963128, 0.97125869, 0.99651403, 1.        , 0.99773461,\n",
       "        0.99936958, 0.9978711 , 0.99776211, 0.9996193 , 0.96754144,\n",
       "        0.99877105, 0.99913725],\n",
       "       [0.99512402, 0.99854622, 0.99791619, 0.99736553, 0.99562086,\n",
       "        0.99657858, 0.9801121 , 0.99497372, 0.99773461, 1.        ,\n",
       "        0.99814986, 0.99800316, 0.9980508 , 0.99722176, 0.97373705,\n",
       "        0.99653565, 0.9977037 ],\n",
       "       [0.99566465, 0.99869774, 0.99928982, 0.99929694, 0.99595091,\n",
       "        0.99894003, 0.97352418, 0.99651817, 0.99936958, 0.99814986,\n",
       "        1.        , 0.99815482, 0.9981109 , 0.99915692, 0.97010877,\n",
       "        0.99834874, 0.99891306],\n",
       "       [0.99468465, 0.99812797, 0.99789648, 0.99763979, 0.99541835,\n",
       "        0.99684643, 0.97782985, 0.99579263, 0.9978711 , 0.99800316,\n",
       "        0.99815482, 1.        , 0.99764864, 0.99741142, 0.97348142,\n",
       "        0.99652877, 0.99761752],\n",
       "       [0.99510445, 0.99797965, 0.9978941 , 0.99757971, 0.99558296,\n",
       "        0.99690875, 0.97697623, 0.99490862, 0.99776211, 0.9980508 ,\n",
       "        0.9981109 , 0.99764864, 1.        , 0.99733874, 0.97182755,\n",
       "        0.99680413, 0.99756767],\n",
       "       [0.99554181, 0.99823546, 0.99941018, 0.99964525, 0.99546823,\n",
       "        0.99955955, 0.97078765, 0.99630712, 0.9996193 , 0.99722176,\n",
       "        0.99915692, 0.99741142, 0.99733874, 1.        , 0.96682889,\n",
       "        0.99873711, 0.99893571],\n",
       "       [0.96953973, 0.97154531, 0.96858762, 0.96656999, 0.97000559,\n",
       "        0.96492698, 0.96870977, 0.97043658, 0.96754144, 0.97373705,\n",
       "        0.97010877, 0.97348142, 0.97182755, 0.96682889, 1.        ,\n",
       "        0.96729074, 0.96910866],\n",
       "       [0.99503323, 0.99753358, 0.99865675, 0.99882205, 0.99466321,\n",
       "        0.99881262, 0.96917797, 0.99605613, 0.99877105, 0.99653565,\n",
       "        0.99834874, 0.99652877, 0.99680413, 0.99873711, 0.96729074,\n",
       "        1.        , 0.99834434],\n",
       "       [0.9954954 , 0.99831295, 0.99908913, 0.99913428, 0.99557276,\n",
       "        0.99891396, 0.97255484, 0.99604521, 0.99913725, 0.9977037 ,\n",
       "        0.99891306, 0.99761752, 0.99756767, 0.99893571, 0.96910866,\n",
       "        0.99834434, 1.        ]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main antiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "feature_engineering_method = []\n",
    "algoritmo=[]\n",
    "accuracy = []\n",
    "precision = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "\n",
    "def main():\n",
    "    df_business_filadelfia,df_review_filadelfia,df_user_filadelfia = load_data()\n",
    "\n",
    "    df_business_filadelfia=df_business_filadelfia.sample(1000)\n",
    "    df_review_filadelfia=df_review_filadelfia.sample(1000)\n",
    "    df_user_filadelfia=df_user_filadelfia.sample(1000)\n",
    "\n",
    "    for a in methods_pre_processing:\n",
    "        df_review_filadelfia_pre_processado = pre_processing(df_review_filadelfia,a)\n",
    "        # print(df_business_filadelfia)\n",
    "        # print(df_review_filadelfia)\n",
    "        # print(df_user_filadelfia)\n",
    "\n",
    "        for b in methods_feature_engineering:\n",
    "            feature_engineering_method.append(b)\n",
    "            final_data = feature_engineering(df_review_filadelfia_pre_processado,b)\n",
    "            # print(final_data)\n",
    "            for c in add_features_decision:\n",
    "                # print(a,b,c)\n",
    "                if c == 'yes':\n",
    "                    # business_data,users_data = add_features(final_data,df_business_filadelfia,df_review_filadelfia,df_user_filadelfia) #adicionamos as repetivas features a cada matriz\n",
    "                    colunas = add_features(final_data,df_business_filadelfia,df_review_filadelfia,df_user_filadelfia) #adicionamos as repetivas features a cada matriz\n",
    "                    print(colunas)\n",
    "                # else:\n",
    "                #     business_data=final_data\n",
    "                #     users_data=final_data\n",
    "                \n",
    "                # general_trainset, general_testset,user_trainset, user_testset,business_trainset, business_testset = split_data(final_data,business_data,users_data)\n",
    "\n",
    "                # print('general_trainset')\n",
    "                # print(general_trainset)\n",
    "\n",
    "                # print('general_testset')\n",
    "                # print(general_testset)\n",
    "\n",
    "                # print('user_trainset')\n",
    "                # print(user_trainset)\n",
    "\n",
    "                # print('user_testset')\n",
    "                # print(user_testset)\n",
    "\n",
    "                # print('business_trainset')\n",
    "                # print(business_trainset)\n",
    "\n",
    "                # print('business_testset')\n",
    "                # print(business_testset)\n",
    "\n",
    "    #             for d in algorithms:\n",
    "    #                 algoritmo.append(d)\n",
    "\n",
    "    #                 if d == 'CF-UB':\n",
    "    #                     algo = KNNBasic(sim_options={'user_based': True})\n",
    "    #                     algo.fit(user_trainset)\n",
    "    #                     predictions = algo.test(user_testset)\n",
    "\n",
    "    #                 elif d == 'CF-IB':\n",
    "    #                     algo = KNNBasic(sim_options={'user_based': False})\n",
    "    #                     algo.fit(business_trainset)\n",
    "    #                     predictions = algo.test(business_testset)\n",
    "\n",
    "    #                 elif d == 'UBH':\n",
    "    #                     similarity_matrix = cosine_similarity(user_trainset)\n",
    "    #                     similarity_matrix = pd.DataFrame(similarity_matrix, index=user_trainset.index, columns=user_trainset.index)\n",
    "\n",
    "    #                     for user_id in user_testset['user_id']:\n",
    "    #                         similar_users = get_top_n_similar_users(user_id, n=5)\n",
    "    #                         recommended_restaurants = get_recommended_restaurants(user_id, similar_users, n_restaurants=5)\n",
    "    #                         best_restaurant = recommended_restaurants.idxmax()\n",
    "\n",
    "\n",
    "    #                 elif d == 'IBH':\n",
    "    #                     for business_id in business_testset['business_id']:\n",
    "    #                         similarity_matrix = cosine_similarity(business_trainset)\n",
    "    #                         similarity_matrix = pd.DataFrame(similarity_matrix, index=business_trainset.index, columns=business_trainset.index)\n",
    "\n",
    "    #                         recommendations = recommend_for_user(user_id, philly_restaurants, algo, similarity_matrix, n=5)\n",
    "\n",
    "\n",
    "    #                 elif d == 'UIBH':\n",
    "    #                     similarity_matrix = cosine_similarity(user_trainset,business_trainset)\n",
    "    #                     similarity_matrix = pd.DataFrame(similarity_matrix, index=user_trainset.index, columns=business_trainset.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_restaurants(restaurant_id, philly_restaurants, similarity_matrix, n=5):\n",
    "    # Obter o índice do restaurante\n",
    "    idx = philly_restaurants.index[philly_restaurants['business_id'] == restaurant_id].tolist()[0]\n",
    "    \n",
    "    # Obter similaridade do restaurante com todos os outros\n",
    "    similars_indices = similarity_matrix[idx].argsort()[::-1]  # Do mais similar para o menos similar\n",
    "    \n",
    "    # Excluir o próprio restaurante da recomendação\n",
    "    similars_indices = similars_indices[similars_indices != idx]\n",
    "    \n",
    "    # Selecionar os n mais similares\n",
    "    similars_restaurants = philly_restaurants.iloc[similars_indices[:n]]\n",
    "    \n",
    "    return similars_restaurants[['business_id', 'name', 'categories', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para recomendar com base nos restaurantes que o usuário já avaliou bem\n",
    "def recommend_for_user(user_id, philly_restaurants, algo, similarity_matrix, n=5):\n",
    "    # Obter os restaurantes avaliados pelo usuário\n",
    "    user_reviews = ratings[ratings['user_id'] == user_id]\n",
    "    highly_rated = user_reviews[user_reviews['stars'] >= 4]['business_id']\n",
    "    \n",
    "    # Para cada restaurante que o usuário gostou, recomendar restaurantes similares\n",
    "    recommendations = pd.DataFrame()\n",
    "    # print('highly rated ',highly_rated)\n",
    "\n",
    "    for restaurant_id in highly_rated:\n",
    "        try:\n",
    "            # Obter o índice do restaurante\n",
    "            inner_id = algo.trainset.to_inner_iid(restaurant_id)\n",
    "            \n",
    "            # Obter os restaurantes mais similares usando o modelo treinado\n",
    "            neighbors = algo.get_neighbors(inner_id, k=n)\n",
    "            # print('neighbors ',neighbors)\n",
    "            # Converter os índices internos para IDs de restaurantes\n",
    "            similar_restaurant_ids_knn = [algo.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n",
    "            \n",
    "            # Obter os detalhes dos restaurantes similares usando o modelo treinado\n",
    "            similar_restaurants_knn = philly_restaurants[philly_restaurants['business_id'].isin(similar_restaurant_ids_knn)]\n",
    "            # print('similar_restaurants_knn ',similar_restaurants_knn)\n",
    "        except ValueError:\n",
    "            # Se o restaurante não estiver no conjunto de treino, retornar um DataFrame vazio\n",
    "            similar_restaurants_knn = pd.DataFrame()\n",
    "        \n",
    "        # Obter os detalhes dos restaurantes similares usando a matriz de similaridade\n",
    "        similar_restaurants_matrix = recommend_similar_restaurants(restaurant_id, philly_restaurants, similarity_matrix, n)\n",
    "        # print('similar_restaurants_matrix ',similar_restaurants_matrix)\n",
    "        # Combinar as recomendações de ambos os métodos\n",
    "        combined_recommendations = pd.concat([similar_restaurants_knn, similar_restaurants_matrix]).drop_duplicates(subset='business_id')\n",
    "        \n",
    "        recommendations = pd.concat([recommendations, combined_recommendations])\n",
    "        # print('recommendations ',recommendations)\n",
    "    # Remover duplicatas e ordenar por popularidade (opcional: você pode melhorar o critério de ordenação)\n",
    "    recommendations = recommendations.drop_duplicates(subset='name').sort_values(by='stars', ascending=False)\n",
    "    # print('recommendations ',recommendations)\n",
    "    return recommendations['name'].head(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_similar_users(user_id, n,similarity_matrix,user_trainset):\n",
    "    if user_id in similarity_matrix.index:\n",
    "        similar_users = similarity_matrix[user_id].sort_values(ascending=False).index[1:n+1]\n",
    "    else:\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        knn = NearestNeighbors(n_neighbors=n, metric='cosine')\n",
    "        knn.fit(user_trainset)\n",
    "        distances, indices = knn.kneighbors(user_trainset.loc[user_id].values.reshape(1, -1), n_neighbors=n+1)\n",
    "        similar_users = user_trainset.index[indices.flatten()][1:]\n",
    "    return similar_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_restaurants(user_id, similar_users, n,user_trainset):\n",
    "    target_user_ratings = user_trainset.loc[user_id]\n",
    "    target_user_visited = target_user_ratings[target_user_ratings > 0].index\n",
    "\n",
    "    similar_users_ratings = user_trainset.loc[similar_users]\n",
    "    similar_users_ratings = similar_users_ratings.drop(columns=target_user_visited, errors='ignore')\n",
    "\n",
    "    top_rated_restaurants = similar_users_ratings.mean().sort_values(ascending=False).head(n)\n",
    "    return top_rated_restaurants\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
